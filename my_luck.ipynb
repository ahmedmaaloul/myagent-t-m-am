{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91d41ff5",
   "metadata": {},
   "source": [
    "## 🔧 Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ab9de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (2.7.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch==2.7.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch==2.7.1->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.22.1-cp312-cp312-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.22.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4858f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290cc75",
   "metadata": {},
   "source": [
    "I have a mac :\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bafef5",
   "metadata": {},
   "source": [
    "## 📦 Dataset Load & Preprocessing\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a3448e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting num_proc from 8 to 2 for the train split as it only contains 2 shards.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c99f48def4454a82e82b9deab28883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/147289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting num_proc from 8 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697e9e8ab7b84512991ee3f008021bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting num_proc from 8 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1539b81514141d6bc9a1a9e2d6e0d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/8204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6bdb1ec0b54d99b7d685c7c47515bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb6dfd35ce94852b22b0194b8e2dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea685506a384204aff79ee531cf0d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/147289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7620fe7c334035a01fe3ae566cb8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns now: ['image', 'input_ids', 'attention_mask']\n",
      "Sample shapes — img: torch.Size([3, 224, 224]) | ids: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "# 1️⃣  Load data\n",
    "ds_train, ds_test = load_dataset(\n",
    "    \"CADCODER/GenCAD-Code\",\n",
    "    split=[\"train\", \"test\"],\n",
    "    num_proc=8          # 8 is usually plenty on an M1 Pro\n",
    ")\n",
    "\n",
    "# 2️⃣  Image transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def preprocess(example):\n",
    "    \"\"\"\n",
    "    - Resize image & convert to tensor\n",
    "    - Keep the CADQuery script under the key `cadquery`\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"image\": transform(example[\"image\"].convert(\"RGB\")),\n",
    "        \"cadquery\": example[\"cadquery\"],\n",
    "    }\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_test  = ds_test.map(preprocess)\n",
    "\n",
    "# 3️⃣  Tokeniser (GPT-2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token      # GPT-2 has no pad token by default\n",
    "\n",
    "def tokenize(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"cadquery\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    example[\"input_ids\"] = tokens[\"input_ids\"][0]\n",
    "    example[\"attention_mask\"] = tokens[\"attention_mask\"][0]\n",
    "    return example\n",
    "\n",
    "# Keep only what we need: image + tokenised IDs/mask\n",
    "keep_cols = [\"image\", \"input_ids\", \"attention_mask\"]\n",
    "\n",
    "ds_train = ds_train.map(tokenize, remove_columns=[c for c in ds_train.column_names if c not in keep_cols])\n",
    "ds_test  = ds_test.map(tokenize,  remove_columns=[c for c in ds_test.column_names  if c not in keep_cols])\n",
    "\n",
    "# 4️⃣  Tell 🤗 Datasets to yield PyTorch tensors\n",
    "ds_train.set_format(type=\"torch\")\n",
    "ds_test.set_format(type=\"torch\")\n",
    "\n",
    "print(\"Columns now:\", ds_train.column_names)\n",
    "print(\"Sample shapes — img:\", ds_train[0][\"image\"].shape,\n",
    "      \"| ids:\", ds_train[0][\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdbdf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.22.1)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250629-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250628-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250627-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250626-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250625-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250624-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250623-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250622-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250621-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250620-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250619-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250618-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250617-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250616-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250615-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250614-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250613-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250612-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250611-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250610-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250609-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250608-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250607-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250606-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250605-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250604-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250603-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250602-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250601-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torchaudio-2.8.0.dev20250531-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "  Downloading torchaudio-2.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torchaudio-2.7.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeaac403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())   # → True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220f606a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b376da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8              # fits into 16 GB unified memory\n",
    "NUM_WORKERS = 4             # safe on M1 Pro\n",
    "\n",
    "train_loader = DataLoader(ds_train, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader  = DataLoader(ds_test,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15180a7",
   "metadata": {},
   "source": [
    "## Baseline model (ResNet18 encoder + LSTM decoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4619b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class Img2Code(nn.Module):\n",
    "    def __init__(self, vocab, embed=256, hidden=512):\n",
    "        super().__init__()\n",
    "\n",
    "        # ➊ image encoder (pre-trained ResNet18, last layer replaced)\n",
    "        self.cnn = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, embed)\n",
    "\n",
    "        # ➋ text decoder\n",
    "        self.embed = nn.Embedding(vocab, embed)\n",
    "        self.lstm  = nn.LSTM(embed, hidden, batch_first=True)\n",
    "        self.fc    = nn.Linear(hidden, vocab)\n",
    "\n",
    "    def forward(self, img, seq):\n",
    "        \"\"\"\n",
    "        img : [B,3,224,224]\n",
    "        seq : [B,T]   (teacher forcing tokens)\n",
    "        \"\"\"\n",
    "        feat = self.cnn(img)                       # [B,embed]\n",
    "        emb  = self.embed(seq)                     # [B,T,embed]\n",
    "        emb[:,0,:] = feat                          # inject image at <bos>\n",
    "        out, _ = self.lstm(emb)\n",
    "        return self.fc(out)                        # [B,T,vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ef64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Img2Code(len(tokenizer)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6557f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "EPOCHS = 1        # adjust ↑ when you have more time\n",
    "LR     = 1e-4\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for batch in train_loader:\n",
    "        imgs  = batch[\"image\"].to(DEVICE)\n",
    "        ids   = batch[\"input_ids\"].to(DEVICE)\n",
    "\n",
    "        # Teacher forcing: predict token t+1 from tokens ≤ t\n",
    "        logits = model(imgs, ids[:,:-1])\n",
    "        loss   = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            ids[:,1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | loss = {total/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fea8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate(img, max_len=120):\n",
    "    model.eval()\n",
    "    img = img.unsqueeze(0).to(DEVICE)\n",
    "    seq = torch.tensor([[tokenizer.bos_token_id]], device=DEVICE)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        logits = model(img, seq)\n",
    "        next_id = logits[:,-1].argmax(-1, keepdim=True)\n",
    "        seq = torch.cat([seq, next_id], dim=1)\n",
    "        if next_id.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(seq[0,1:].tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f03f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.valid_syntax_rate import evaluate_syntax_rate_simple\n",
    "from metrics.best_iou import get_iou_best\n",
    "\n",
    "# ── generate for 10 test samples just to check the pipeline ──\n",
    "codes_pred, codes_gt = {}, {}\n",
    "for i, sample in enumerate(ds_test.shuffle(seed=42).select(range(10))):\n",
    "    gen_code = generate(sample[\"image\"].to(DEVICE))\n",
    "    codes_pred[f\"pred_{i}\"] = gen_code\n",
    "    codes_gt  [f\"pred_{i}\"] = sample[\"cadquery\"]\n",
    "\n",
    "vsr = evaluate_syntax_rate_simple(codes_pred)\n",
    "print(\"Valid-syntax rate (10 samples):\", vsr)\n",
    "\n",
    "ious = [get_iou_best(codes_pred[k], codes_gt[k]) for k in codes_pred]\n",
    "print(\"Avg IOU (10 samples):\", sum(ious)/len(ious))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51d3a4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
